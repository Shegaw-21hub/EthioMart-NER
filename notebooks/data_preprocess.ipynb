{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed file saved at: ../data/processed\\telegram_messages_20250621_052911_cleaned.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>💥💥...................................💥💥\\n\\n📌Im...</td>\n",
       "      <td>Imitation Volcano Humidifier with LED Light በኤ...</td>\n",
       "      <td>[Imitation, Volcano, Humidifier, with, LED, Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>💥💥...................................💥💥\\n\\n📌 B...</td>\n",
       "      <td>Baby Carrier በፈለጉት አቅጣጫ ልጅዎን በምቾት ማዘል ያስችልዎታል ...</td>\n",
       "      <td>[Baby, Carrier, በፈለጉት, አቅጣጫ, ልጅዎን, በምቾት, ማዘል, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>💥💥...................................💥💥\\n\\n📌Sm...</td>\n",
       "      <td>Smart Usb Ultrasonic Car And Home Air Humidifi...</td>\n",
       "      <td>[Smart, Usb, Ultrasonic, Car, And, Home, Air, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  💥💥...................................💥💥\\n\\n📌Im...   \n",
       "1  💥💥...................................💥💥\\n\\n📌 B...   \n",
       "2  💥💥...................................💥💥\\n\\n📌Sm...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  Imitation Volcano Humidifier with LED Light በኤ...   \n",
       "1  Baby Carrier በፈለጉት አቅጣጫ ልጅዎን በምቾት ማዘል ያስችልዎታል ...   \n",
       "2  Smart Usb Ultrasonic Car And Home Air Humidifi...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [Imitation, Volcano, Humidifier, with, LED, Li...  \n",
       "1  [Baby, Carrier, በፈለጉት, አቅጣጫ, ልጅዎን, በምቾት, ማዘል, ...  \n",
       "2  [Smart, Usb, Ultrasonic, Car, And, Home, Air, ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 📦 Imports\n",
    "import re\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import os\n",
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 🧼 Cleaning function\n",
    "def clean_amharic_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = emoji.replace_emoji(text, replace='')\n",
    "    text = re.sub(r'\\.{3,}', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s\\u1200-\\u137F.,!?]', '', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text.strip()\n",
    "\n",
    "# 📂 Load data from .json or .csv\n",
    "def load_data(input_path):\n",
    "    ext = os.path.splitext(input_path)[-1].lower()\n",
    "    if ext == \".json\":\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        df = pd.DataFrame(data)\n",
    "    elif ext == \".csv\":\n",
    "        df = pd.read_csv(input_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {ext}\")\n",
    "    if \"text\" not in df.columns:\n",
    "        raise KeyError(\"'text' column not found in input file.\")\n",
    "    return df\n",
    "\n",
    "# 🧹 Clean + tokenize\n",
    "def preprocess_dataframe(df):\n",
    "    df[\"cleaned_text\"] = df[\"text\"].apply(clean_amharic_text)\n",
    "    df[\"tokens\"] = df[\"cleaned_text\"].apply(word_tokenize)\n",
    "    df = df[df[\"cleaned_text\"].str.strip() != \"\"]\n",
    "    return df\n",
    "\n",
    "# 💾 Save the processed dataframe\n",
    "def save_processed(df, input_path):\n",
    "    # Set output directory and file name\n",
    "    base_dir = os.path.dirname(input_path).replace(\"raw\", \"processed\")\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    file_name = os.path.splitext(os.path.basename(input_path))[0] + \"_cleaned.csv\"\n",
    "    output_path = os.path.join(base_dir, file_name)\n",
    "\n",
    "    df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"✅ Processed file saved at: {output_path}\")\n",
    "\n",
    "# 🛠️ Input path\n",
    "input_path = \"../data/raw/telegram_messages_20250621_052911.json\"  # or .csv\n",
    "\n",
    "# 🚀 Run pipeline\n",
    "df_raw = load_data(input_path)\n",
    "df_processed = preprocess_dataframe(df_raw)\n",
    "save_processed(df_processed, input_path)\n",
    "\n",
    "# 🔍 Preview\n",
    "df_processed[[\"text\", \"cleaned_text\", \"tokens\"]].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with decorative symbols: 0\n",
      "✅ No decorative symbols found in cleaned_text.\n",
      "✅ No decorative symbols in tokens.\n"
     ]
    }
   ],
   "source": [
    "df_with_symbols = df_processed[df_processed['cleaned_text'].str.contains(r'[💥\\.]{5,}', regex=True)]\n",
    "\n",
    "print(f\"Rows with decorative symbols: {len(df_with_symbols)}\")\n",
    "if not df_with_symbols.empty:\n",
    "    print(df_with_symbols[['text']].head(3))\n",
    "else:\n",
    "    print(\"✅ No decorative symbols found in cleaned_text.\")\n",
    "from itertools import chain\n",
    "\n",
    "tokens_flat = list(chain.from_iterable(df_processed['tokens']))\n",
    "suspicious_tokens = [tok for tok in tokens_flat if re.fullmatch(r'[💥\\.]{3,}', tok)]\n",
    "\n",
    "if suspicious_tokens:\n",
    "    print(\"⚠️ Found suspicious tokens:\", suspicious_tokens[:5])\n",
    "else:\n",
    "    print(\"✅ No decorative symbols in tokens.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
